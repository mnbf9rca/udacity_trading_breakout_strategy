{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Project 2: Breakout Strategy\n",
    "## Instructions\n",
    "Each problem consists of a function to implement and instructions on how to implement the function.  The parts of the function that need to be implemented are marked with a `# TODO` comment. After implementing the function, run the cell to test it against the unit tests we've provided. For each problem, we provide one or more unit tests from our `project_tests` package. These unit tests won't tell you if your answer is correct, but will warn you of any major errors. Your code will be checked for the correct solution when you submit it to Udacity.\n",
    "\n",
    "## Packages\n",
    "When you implement the functions, you'll only need to you use the packages you've used in the classroom, like [Pandas](https://pandas.pydata.org/) and [Numpy](http://www.numpy.org/). These packages will be imported for you. We recommend you don't add any import statements, otherwise the grader might not be able to run your code.\n",
    "\n",
    "The other packages that we're importing are `helper`, `project_helper`, and `project_tests`. These are custom packages built to help you solve the problems.  The `helper` and `project_helper` module contains utility functions and graph functions. The `project_tests` contains the unit tests for all the problems.\n",
    "\n",
    "### Install Packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: colour==0.1.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (0.1.5)\n",
      "Collecting cvxpy==1.0.3 (from -r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/59/2613468ffbbe3a818934d06b81b9f4877fe054afbf4f99d2f43f398a0b34/cvxpy-1.0.3.tar.gz (880kB)\n",
      "\u001b[K    100% |████████████████████████████████| 880kB 14.4MB/s ta 0:00:01    29% |█████████▎                      | 256kB 12.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler==0.10.0 in /opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from -r requirements.txt (line 3)) (0.10.0)\n",
      "Collecting numpy==1.13.3 (from -r requirements.txt (line 4))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/a7/e3e6bd9d595125e1abbe162e323fd2d06f6f6683185294b79cd2cdb190d5/numpy-1.13.3-cp36-cp36m-manylinux1_x86_64.whl (17.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.0MB 2.4MB/s eta 0:00:01  9% |███                             | 1.6MB 22.3MB/s eta 0:00:01    28% |█████████▏                      | 4.9MB 20.3MB/s eta 0:00:01    46% |███████████████                 | 7.9MB 19.2MB/s eta 0:00:01    56% |██████████████████▏             | 9.7MB 20.8MB/s eta 0:00:01    63% |████████████████████▏           | 10.7MB 20.1MB/s eta 0:00:01    68% |██████████████████████          | 11.6MB 18.1MB/s eta 0:00:01    74% |████████████████████████        | 12.7MB 22.9MB/s eta 0:00:01    99% |███████████████████████████████▊| 16.9MB 23.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==0.21.1 (from -r requirements.txt (line 5))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/e1/6c514df670b887c77838ab856f57783c07e8760f2e3d5939203a39735e0e/pandas-0.21.1-cp36-cp36m-manylinux1_x86_64.whl (26.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.2MB 1.6MB/s eta 0:00:01  2% |▊                               | 573kB 23.3MB/s eta 0:00:02    6% |██                              | 1.7MB 24.0MB/s eta 0:00:02    19% |██████▏                         | 5.0MB 23.2MB/s eta 0:00:01    35% |███████████▌                    | 9.4MB 22.3MB/s eta 0:00:01    39% |████████████▊                   | 10.5MB 19.3MB/s eta 0:00:01    47% |███████████████▎                | 12.5MB 18.5MB/s eta 0:00:01    67% |█████████████████████▌          | 17.6MB 21.4MB/s eta 0:00:01    75% |████████████████████████        | 19.7MB 21.1MB/s eta 0:00:01    78% |█████████████████████████▎      | 20.7MB 22.2MB/s eta 0:00:01    92% |█████████████████████████████▋  | 24.3MB 5.1MB/s eta 0:00:01    96% |██████████████████████████████▉ | 25.2MB 20.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly==2.2.3 (from -r requirements.txt (line 6))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/a6/8214b6564bf4ace9bec8a26e7f89832792be582c042c47c912d3201328a0/plotly-2.2.3.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 14.1MB/s ta 0:00:01    45% |██████████████▌                 | 491kB 20.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing==2.2.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil==2.6.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: pytz==2017.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9)) (2017.3)\n",
      "Requirement already satisfied: requests==2.18.4 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10)) (2.18.4)\n",
      "Collecting scipy==1.0.0 (from -r requirements.txt (line 11))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/5e/caa01ba7be11600b6a9d39265440d7b3be3d69206da887c42bef049521f2/scipy-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (50.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 50.0MB 722kB/s eta 0:00:01  9% |███                             | 4.6MB 18.7MB/s eta 0:00:03    11% |███▌                            | 5.5MB 19.3MB/s eta 0:00:03    18% |█████▉                          | 9.1MB 16.8MB/s eta 0:00:03    23% |███████▌                        | 11.8MB 16.7MB/s eta 0:00:03    25% |████████                        | 12.7MB 17.8MB/s eta 0:00:03    27% |████████▊                       | 13.6MB 17.8MB/s eta 0:00:03    28% |█████████▎                      | 14.4MB 17.5MB/s eta 0:00:03    32% |██████████▌                     | 16.3MB 20.3MB/s eta 0:00:02    34% |███████████                     | 17.3MB 20.9MB/s eta 0:00:02    36% |███████████▋                    | 18.1MB 18.6MB/s eta 0:00:02    38% |████████████▏                   | 19.1MB 19.1MB/s eta 0:00:02    39% |████████████▊                   | 19.9MB 17.2MB/s eta 0:00:02    41% |█████████████▎                  | 20.8MB 18.5MB/s eta 0:00:02    45% |██████████████▍                 | 22.6MB 16.5MB/s eta 0:00:02    48% |███████████████▋                | 24.4MB 17.5MB/s eta 0:00:02    50% |████████████████▏               | 25.3MB 18.5MB/s eta 0:00:02    52% |████████████████▊               | 26.1MB 19.0MB/s eta 0:00:02    60% |███████████████████▍            | 30.4MB 15.0MB/s eta 0:00:02    62% |███████████████████▉            | 31.1MB 12.8MB/s eta 0:00:02    63% |████████████████████▎           | 31.6MB 10.0MB/s eta 0:00:02    66% |█████████████████████▏          | 33.2MB 10.5MB/s eta 0:00:02    67% |█████████████████████▋          | 33.7MB 10.9MB/s eta 0:00:02    68% |██████████████████████          | 34.3MB 10.0MB/s eta 0:00:02    69% |██████████████████████▎         | 34.8MB 11.1MB/s eta 0:00:02    74% |████████████████████████        | 37.4MB 9.1MB/s eta 0:00:02    76% |████████████████████████▋       | 38.5MB 8.1MB/s eta 0:00:02    80% |█████████████████████████▊      | 40.2MB 12.3MB/s eta 0:00:01    81% |██████████████████████████      | 40.8MB 12.2MB/s eta 0:00:01    82% |██████████████████████████▍     | 41.3MB 9.8MB/s eta 0:00:01    83% |██████████████████████████▊     | 41.8MB 8.4MB/s eta 0:00:01    84% |███████████████████████████     | 42.3MB 10.0MB/s eta 0:00:01    85% |███████████████████████████▍    | 42.9MB 11.9MB/s eta 0:00:01    87% |███████████████████████████▉    | 43.5MB 20.2MB/s eta 0:00:01    89% |████████████████████████████▊   | 44.9MB 8.0MB/s eta 0:00:01    96% |██████████████████████████████▉ | 48.3MB 19.1MB/s eta 0:00:01    99% |███████████████████████████████▊| 49.7MB 17.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.19.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 12)) (0.19.1)\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13)) (1.11.0)\n",
      "Collecting tqdm==4.19.5 (from -r requirements.txt (line 14))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/3c/341b4fa23cb3abc335207dba057c790f3bb329f6757e1fcd5d347bcf8308/tqdm-4.19.5-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 8.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting zipline==1.2.0 (from -r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d3/689f2a940478b82ac57c751a40460598221fd82b0449a7a8f7eef47a3bcc/zipline-1.2.0.tar.gz (659kB)\n",
      "\u001b[K    100% |████████████████████████████████| 665kB 16.5MB/s ta 0:00:01    51% |████████████████▍               | 337kB 18.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting osqp (from cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/82/b0693a167e4b9b5e94f4988f6df3d7866e9e41a316a58f1053dd21370f1a/osqp-0.6.2.post0-cp36-cp36m-manylinux1_x86_64.whl (211kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 14.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting ecos>=2 (from cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/ed/d131ff51f3a8f73420eb1191345eb49f269f23cadef515172e356018cde3/ecos-2.0.7.post1-cp36-cp36m-manylinux1_x86_64.whl (147kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 14.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scs>=1.1.3 (from cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/f3/7e11e9c0dc22c2bf2e8b4be1ade4fb8055dbe9ea29fd9bda455844b9d7ca/scs-2.1.4.tar.gz (6.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.6MB 5.4MB/s eta 0:00:01   3% |█▏                              | 245kB 18.9MB/s eta 0:00:01    33% |██████████▊                     | 2.2MB 23.5MB/s eta 0:00:01    49% |███████████████▉                | 3.2MB 21.3MB/s eta 0:00:01    75% |████████████████████████▎       | 5.0MB 15.1MB/s eta 0:00:01    91% |█████████████████████████████▎  | 6.0MB 25.7MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting multiprocess (from cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/d0/c3011a5bb77f307e68682a5046cce1a2c6591267bf24b5bf3fc4130bb39d/multiprocess-0.70.12.2-py36-none-any.whl (106kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 7.8MB/s ta 0:00:01   47% |███████████████▎                | 51kB 8.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fastcache in /opt/conda/lib/python3.6/site-packages (from cvxpy==1.0.3->-r requirements.txt (line 2)) (1.0.2)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.6/site-packages (from cvxpy==1.0.3->-r requirements.txt (line 2)) (0.8.2)\n",
      "Requirement already satisfied: decorator>=4.0.6 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 6)) (4.0.11)\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests==2.18.4->-r requirements.txt (line 10)) (2019.11.28)\n",
      "Requirement already satisfied: pip>=7.1.0 in /opt/conda/lib/python3.6/site-packages (from zipline==1.2.0->-r requirements.txt (line 15)) (18.1)\n",
      "Requirement already satisfied: setuptools>18.0 in /opt/conda/lib/python3.6/site-packages (from zipline==1.2.0->-r requirements.txt (line 15)) (38.4.0)\n",
      "Collecting Logbook>=0.12.5 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/d9/16ac346f7c0102835814cc9e5b684aaadea101560bb932a2403bd26b2320/Logbook-1.5.3.tar.gz (85kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 6.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting requests-file>=1.4.1 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
      "Collecting pandas-datareader<0.6,>=0.2.1 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/c5/cc720f531bbde0efeab940de400d0fcc95e87770a3abcd7f90d6d52a3302/pandas_datareader-0.5.0-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 9.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: patsy>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from zipline==1.2.0->-r requirements.txt (line 15)) (0.4.1)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline==1.2.0->-r requirements.txt (line 15)) (0.8.0)\n",
      "Requirement already satisfied: Cython>=0.25.2 in /opt/conda/lib/python3.6/site-packages (from zipline==1.2.0->-r requirements.txt (line 15)) (0.29.7)\n",
      "Collecting cyordereddict>=0.2.2 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/1a/364cbfd927be1b743c7f0a985a7f1f7e8a51469619f9fefe4ee9240ba210/cyordereddict-1.0.0.tar.gz (138kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 13.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting bottleneck>=1.0.0 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/08/278c6ee569458e168096f6b51019cc1c81c288da3d1026a22ee2ccead102/Bottleneck-1.3.2.tar.gz (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 8.8MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting contextlib2>=0.4.0 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/76/56/6d6872f79d14c0cb02f1646cbb4592eef935857c0951a105874b7b62a0c3/contextlib2-21.6.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: networkx<2.0,>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from zipline==1.2.0->-r requirements.txt (line 15)) (1.11)\n",
      "Requirement already satisfied: numexpr>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from zipline==1.2.0->-r requirements.txt (line 15)) (2.6.4)\n",
      "Collecting bcolz<1,>=0.12.1 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/8b/1ffa01f872cac36173c5eb95b58c01040d8d25f1b242c48577f4104cd3ab/bcolz-0.12.1.tar.gz (622kB)\n",
      "\u001b[K    100% |████████████████████████████████| 624kB 12.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from zipline==1.2.0->-r requirements.txt (line 15)) (6.7)\n",
      "Collecting multipledispatch>=0.4.8 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/89/79/429ecef45fd5e4504f7474d4c3c3c4668c267be3370e4c2fd33e61506833/multipledispatch-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from zipline==1.2.0->-r requirements.txt (line 15)) (1.0)\n",
      "Requirement already satisfied: Mako>=1.0.1 in /opt/conda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg (from zipline==1.2.0->-r requirements.txt (line 15)) (1.0.7)\n",
      "Requirement already satisfied: sqlalchemy>=1.0.8 in /opt/conda/lib/python3.6/site-packages (from zipline==1.2.0->-r requirements.txt (line 15)) (1.1.13)\n",
      "Collecting alembic>=0.7.7 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a1/bd/f92d3b9c3c82d03b683087711f22e35e36a076efce93a4b4b6e18127d696/alembic-1.7.3-py3-none-any.whl (208kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 16.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting sortedcontainers>=1.4.4 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/32/46/9cb0e58b2deb7f82b84065f37f3bffeb12413f947f9388e4cac22c4621ce/sortedcontainers-2.4.0-py2.py3-none-any.whl\n",
      "Collecting intervaltree>=2.1.0 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/50/fb/396d568039d21344639db96d940d40eb62befe704ef849b27949ded5c3bb/intervaltree-3.1.0.tar.gz\n",
      "Collecting lru-dict>=1.1.4 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/68/ea/997af58d4e6da019ad825a412f93081d9df67e9dda11cfb026a3d7cd0b6c/lru-dict-1.1.7.tar.gz\n",
      "Collecting empyrical>=0.4.2 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/43/1b997c21411c6ab7c96dc034e160198272c7a785aeea7654c9bcf98bec83/empyrical-0.5.5.tar.gz (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 7.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tables>=3.3.0 (from zipline==1.2.0->-r requirements.txt (line 15))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.3MB 5.4MB/s eta 0:00:01    20% |██████▋                         | 890kB 19.7MB/s eta 0:00:01    41% |█████████████▍                  | 1.8MB 17.7MB/s eta 0:00:01    60% |███████████████████▎            | 2.6MB 15.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting qdldl (from osqp->cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/a3/db0e7c9fec5387dc33cbd2819329c141ba76497148aa9fab4bd1a7c2a279/qdldl-0.1.5.post0.tar.gz (69kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 7.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting dill>=0.3.4 (from multiprocess->cvxpy==1.0.3->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/c3/973676ceb86b60835bb3978c6db67a5dc06be6cfdbd14ef0f5a13e3fc9fd/dill-0.3.4-py2.py3-none-any.whl (86kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 9.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (4.4.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (2.6.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 6)) (4.3.2)\n",
      "Collecting requests-ftp (from pandas-datareader<0.6,>=0.2.1->zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/3d/ca/14b2ad1e93b5195eeaf56b86b7ecfd5ea2d5754a68d17aeb1e5b9f95b3cf/requests-ftp-0.3.1.tar.gz\n",
      "Collecting importlib-resources; python_version < \"3.9\" (from alembic>=0.7.7->zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/f2/6c/2f3b930513bb971172ffceb63cf4e910944e57451724e69b1dec97cfefa6/importlib_resources-5.2.2-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from alembic>=0.7.7->zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/c2/cb1855f0b2a0ae9ccc9b69f150a7aebd4a8d815bd951e74621c4154c52a8/importlib_metadata-4.8.1-py3-none-any.whl\n",
      "Collecting zipp>=3.1.0; python_version < \"3.10\" (from importlib-resources; python_version < \"3.9\"->alembic>=0.7.7->zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/92/d9/89f433969fb8dc5b9cbdd4b4deb587720ec1aeb59a020cf15002b9593eef/zipp-3.5.0-py3-none-any.whl\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\" (from importlib-metadata; python_version < \"3.8\"->alembic>=0.7.7->zipline==1.2.0->-r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/60/18783336cc7fcdd95dae91d73477830aa53f5d3181ae4fe20491d7fc3199/typing_extensions-3.10.0.2-py3-none-any.whl\n",
      "Building wheels for collected packages: cvxpy, plotly, zipline, scs, Logbook, cyordereddict, bottleneck, bcolz, intervaltree, lru-dict, empyrical, qdldl, requests-ftp\n",
      "  Running setup.py bdist_wheel for cvxpy ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2b/60/0b/0c2596528665e21d698d6f84a3406c52044c7b4ca6ac737cf3\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/98/54/81/dd92d5b0858fac680cd7bdb8800eb26c001dd9f5dc8b1bc0ba\n",
      "  Running setup.py bdist_wheel for zipline ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5d/20/7d/b48368c8634b1cb6cc7232833b2780a265d4217c0ad2e3d24c\n",
      "  Running setup.py bdist_wheel for scs ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c2/05/3f/9a73cbe83da87283e6db2a2767c3d1a7c1e7ff090342c43bcb\n",
      "  Running setup.py bdist_wheel for Logbook ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d2/70/07/68b99a8e05dcd1ab194a8e0ccb9e4d0ac5dd6d8d139c7149b4\n",
      "  Running setup.py bdist_wheel for cyordereddict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/0b/9d/8b/5bf3e22c1edd59b50f11bb19dec9dfcfe5a479fc7ace02b61f\n",
      "  Running setup.py bdist_wheel for bottleneck ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/a9/12/41b13e8b44889ab05ec4dcc91f27da21634bacf2a0e87473b8\n",
      "  Running setup.py bdist_wheel for bcolz ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c5/cc/1b/2cf1f88959af5d7f4d449b7fc6c9452d0ecbd86fd61a9ee376\n",
      "  Running setup.py bdist_wheel for intervaltree ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/f3/f2/66/e9c30d3e9499e65ea2fa0d07c002e64de63bd0adaa49c445bf\n",
      "  Running setup.py bdist_wheel for lru-dict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ae/51/23/0a416781dead9225c7d66d25b9f223c7e32304e99a0b01d566\n",
      "  Running setup.py bdist_wheel for empyrical ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ea/b2/c8/6769d8444d2f2e608fae2641833110668d0ffd1abeb2e9f3fc\n",
      "  Running setup.py bdist_wheel for qdldl ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a9/77/d6/726fc4a2ae1513b4663b81721f5d75e9b4fe9d74ca7a8a5417\n",
      "  Running setup.py bdist_wheel for requests-ftp ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2a/98/32/37195e45a3392a73d9f65c488cbea30fe5bad76aaef4d6b020\n",
      "Successfully built cvxpy plotly zipline scs Logbook cyordereddict bottleneck bcolz intervaltree lru-dict empyrical qdldl requests-ftp\n",
      "\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\n",
      "\u001b[31mmoviepy 0.2.3.2 has requirement tqdm==4.11.2, but you'll have tqdm 4.19.5 which is incompatible.\u001b[0m\n",
      "\u001b[31malembic 1.7.3 has requirement SQLAlchemy>=1.3.0, but you'll have sqlalchemy 1.1.13 which is incompatible.\u001b[0m\n",
      "\u001b[31mzipline 1.2.0 has requirement pandas<0.19,>=0.18.1, but you'll have pandas 0.21.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, scipy, qdldl, osqp, ecos, scs, dill, multiprocess, cvxpy, pandas, plotly, tqdm, Logbook, requests-file, requests-ftp, pandas-datareader, cyordereddict, bottleneck, contextlib2, bcolz, multipledispatch, zipp, importlib-resources, typing-extensions, importlib-metadata, alembic, sortedcontainers, intervaltree, lru-dict, empyrical, tables, zipline\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: scipy 1.2.1\n",
      "    Uninstalling scipy-1.2.1:\n",
      "      Successfully uninstalled scipy-1.2.1\n",
      "  Found existing installation: dill 0.2.7.1\n",
      "    Uninstalling dill-0.2.7.1:\n",
      "      Successfully uninstalled dill-0.2.7.1\n",
      "  Found existing installation: pandas 0.23.3\n",
      "    Uninstalling pandas-0.23.3:\n",
      "      Successfully uninstalled pandas-0.23.3\n",
      "  Found existing installation: plotly 2.0.15\n",
      "    Uninstalling plotly-2.0.15:\n",
      "      Successfully uninstalled plotly-2.0.15\n",
      "  Found existing installation: tqdm 4.11.2\n",
      "    Uninstalling tqdm-4.11.2:\n",
      "      Successfully uninstalled tqdm-4.11.2\n",
      "Successfully installed Logbook-1.5.3 alembic-1.7.3 bcolz-0.12.1 bottleneck-1.3.2 contextlib2-21.6.0 cvxpy-1.0.3 cyordereddict-1.0.0 dill-0.3.4 ecos-2.0.7.post1 empyrical-0.5.5 importlib-metadata-4.8.1 importlib-resources-5.2.2 intervaltree-3.1.0 lru-dict-1.1.7 multipledispatch-0.6.0 multiprocess-0.70.12.2 numpy-1.13.3 osqp-0.6.2.post0 pandas-0.21.1 pandas-datareader-0.5.0 plotly-2.2.3 qdldl-0.1.5.post0 requests-file-1.5.1 requests-ftp-0.3.1 scipy-1.0.0 scs-2.1.4 sortedcontainers-2.4.0 tables-3.6.1 tqdm-4.19.5 typing-extensions-3.10.0.2 zipline-1.2.0 zipp-3.5.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helper\n",
    "import project_helper\n",
    "import project_tests"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Market Data\n",
    "### Load Data\n",
    "While using real data will give you hands on experience, it's doesn't cover all the topics we try to condense in one project. We'll solve this by creating new stocks. We've create a scenario where companies mining [Terbium](https://en.wikipedia.org/wiki/Terbium) are making huge profits. All the companies in this sector of the market are made up. They represent a sector with large growth that will be used for demonstration latter in this project."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_original = pd.read_csv('../../data/project_2/eod-quotemedia.csv', parse_dates=['date'], index_col=False)\n",
    "\n",
    "# Add TB sector to the market\n",
    "df = df_original\n",
    "df = pd.concat([df] + project_helper.generate_tb_sector(df[df['ticker'] == 'AAPL']['date']), ignore_index=True)\n",
    "\n",
    "close = df.reset_index().pivot(index='date', columns='ticker', values='adj_close')\n",
    "high = df.reset_index().pivot(index='date', columns='ticker', values='adj_high')\n",
    "low = df.reset_index().pivot(index='date', columns='ticker', values='adj_low')\n",
    "\n",
    "print('Loaded Data')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View Data\n",
    "To see what one of these 2-d matrices looks like, let's take a look at the closing prices matrix."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "close"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stock Example\n",
    "Let's see what a single stock looks like from the closing prices. For this example and future display examples in this project, we'll use Apple's stock (AAPL). If we tried to graph all the stocks, it would be too much information."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "apple_ticker = 'AAPL'\n",
    "project_helper.plot_stock(close[apple_ticker], '{} Stock'.format(apple_ticker))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Alpha Research Process\n",
    "\n",
    "In this project you will code and evaluate a \"breakout\" signal. It is important to understand where these steps fit in the alpha research workflow. The signal-to-noise ratio in trading signals is very low and, as such, it is very easy to fall into the trap of _overfitting_ to noise. It is therefore inadvisable to jump right into signal coding. To help mitigate overfitting, it is best to start with a general observation and hypothesis; i.e., you should be able to answer the following question _before_ you touch any data:\n",
    "\n",
    "> What feature of markets or investor behaviour would lead to a persistent anomaly that my signal will try to use?\n",
    "\n",
    "Ideally the assumptions behind the hypothesis will be testable _before_ you actually code and evaluate the signal itself. The workflow therefore is as follows:\n",
    "\n",
    "![image](images/alpha_steps.png)\n",
    "\n",
    "In this project, we assume that the first three steps area done (\"observe & research\", \"form hypothesis\", \"validate hypothesis\"). The hypothesis you'll be using for this project is the following:\n",
    "- In the absence of news or significant investor trading interest, stocks oscillate in a range.\n",
    "- Traders seek to capitalize on this range-bound behaviour periodically by selling/shorting at the top of the range and buying/covering at the bottom of the range. This behaviour reinforces the existence of the range.\n",
    "- When stocks break out of the range, due to, e.g., a significant news release or from market pressure from a large investor:\n",
    "    - the liquidity traders who have been providing liquidity at the bounds of the range seek to cover their positions to mitigate losses, thus magnifying the move out of the range, _and_\n",
    "    - the move out of the range attracts other investor interest; these investors, due to the behavioural bias of _herding_ (e.g., [Herd Behavior](https://www.investopedia.com/university/behavioral_finance/behavioral8.asp)) build positions which favor continuation of the trend.\n",
    "\n",
    "\n",
    "Using this hypothesis, let start coding..\n",
    "## Compute the Highs and Lows in a Window\n",
    "You'll use the price highs and lows as an indicator for the breakout strategy. In this section, implement `get_high_lows_lookback` to get the maximum high price and minimum low price over a window of days. The variable `lookback_days` contains the number of days to look in the past. Make sure this doesn't include the current day."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_high_lows_lookback(high, low, lookback_days):\n",
    "    \"\"\"\n",
    "    Get the highs and lows in a lookback window.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    high : DataFrame\n",
    "        High price for each ticker and date\n",
    "    low : DataFrame\n",
    "        Low price for each ticker and date\n",
    "    lookback_days : int\n",
    "        The number of days to look back\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lookback_high : DataFrame\n",
    "        Lookback high price for each ticker and date\n",
    "    lookback_low : DataFrame\n",
    "        Lookback low price for each ticker and date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None, None\n",
    "\n",
    "project_tests.test_get_high_lows_lookback(get_high_lows_lookback)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View Data\n",
    "Let's use your implementation of `get_high_lows_lookback` to get the highs and lows for the past 50 days and compare it to it their respective stock.  Just like last time, we'll use Apple's stock as the example to look at."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lookback_days = 50\n",
    "lookback_high, lookback_low = get_high_lows_lookback(high, low, lookback_days)\n",
    "project_helper.plot_high_low(\n",
    "    close[apple_ticker],\n",
    "    lookback_high[apple_ticker],\n",
    "    lookback_low[apple_ticker],\n",
    "    'High and Low of {} Stock'.format(apple_ticker))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute Long and Short Signals\n",
    "Using the generated indicator of highs and lows, create long and short signals using a breakout strategy. Implement `get_long_short` to generate the following signals:\n",
    "\n",
    "| Signal | Condition |\n",
    "|----|------|\n",
    "| -1 | Low > Close Price |\n",
    "| 1  | High < Close Price |\n",
    "| 0  | Otherwise |\n",
    "\n",
    "In this chart, **Close Price** is the `close` parameter. **Low** and **High** are the values generated from `get_high_lows_lookback`, the `lookback_high` and `lookback_low` parameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_long_short(close, lookback_high, lookback_low):\n",
    "    \"\"\"\n",
    "    Generate the signals long, short, and do nothing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    close : DataFrame\n",
    "        Close price for each ticker and date\n",
    "    lookback_high : DataFrame\n",
    "        Lookback high price for each ticker and date\n",
    "    lookback_low : DataFrame\n",
    "        Lookback low price for each ticker and date\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    long_short : DataFrame\n",
    "        The long, short, and do nothing signals for each ticker and date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_get_long_short(get_long_short)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View Data\n",
    "Let's compare the signals you generated against the close prices. This chart will show a lot of signals. Too many in fact. We'll talk about filtering the redundant signals in the next problem. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "signal = get_long_short(close, lookback_high, lookback_low)\n",
    "project_helper.plot_signal(\n",
    "    close[apple_ticker],\n",
    "    signal[apple_ticker],\n",
    "    'Long and Short of {} Stock'.format(apple_ticker))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter Signals\n",
    "That was a lot of repeated signals! If we're already shorting a stock, having an additional signal to short a stock isn't helpful for this strategy. This also applies to additional long signals when the last signal was long.\n",
    "\n",
    "Implement `filter_signals` to filter out repeated long or short signals within the `lookahead_days`. If the previous signal was the same, change the signal to `0` (do nothing signal). For example, say you have a single stock time series that is\n",
    "\n",
    "`[1, 0, 1, 0, 1, 0, -1, -1]`\n",
    "\n",
    "Running `filter_signals` with a lookahead of 3 days should turn those signals into\n",
    "\n",
    "`[1, 0, 0, 0, 1, 0, -1, 0]`\n",
    "\n",
    "To help you implement the function, we have provided you with the `clear_signals` function. This will remove all signals within a window after the last signal. For example, say you're using a windows size of 3 with `clear_signals`. It would turn the Series of long signals\n",
    "\n",
    "`[0, 1, 0, 0, 1, 1, 0, 1, 0]`\n",
    "\n",
    "into\n",
    "\n",
    "`[0, 1, 0, 0, 0, 1, 0, 0, 0]`\n",
    "\n",
    "`clear_signals` only takes a Series of the same type of signals, where `1` is the signal and `0` is no signal. It can't take a mix of long and short signals. Using this function, implement `filter_signals`. \n",
    "\n",
    "For implementing `filter_signals`, we don't reccommend you try to find a vectorized solution. Instead, you should use the [`iterrows`](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.iterrows.html) over each column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def clear_signals(signals, window_size):\n",
    "    \"\"\"\n",
    "    Clear out signals in a Series of just long or short signals.\n",
    "    \n",
    "    Remove the number of signals down to 1 within the window size time period.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signals : Pandas Series\n",
    "        The long, short, or do nothing signals\n",
    "    window_size : int\n",
    "        The number of days to have a single signal       \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    signals : Pandas Series\n",
    "        Signals with the signals removed from the window size\n",
    "    \"\"\"\n",
    "    # Start with buffer of window size\n",
    "    # This handles the edge case of calculating past_signal in the beginning\n",
    "    clean_signals = [0]*window_size\n",
    "    \n",
    "    for signal_i, current_signal in enumerate(signals):\n",
    "        # Check if there was a signal in the past window_size of days\n",
    "        has_past_signal = bool(sum(clean_signals[signal_i:signal_i+window_size]))\n",
    "        # Use the current signal if there's no past signal, else 0/False\n",
    "        clean_signals.append(not has_past_signal and current_signal)\n",
    "        \n",
    "    # Remove buffer\n",
    "    clean_signals = clean_signals[window_size:]\n",
    "\n",
    "    # Return the signals as a Series of Ints\n",
    "    return pd.Series(np.array(clean_signals).astype(np.int), signals.index)\n",
    "\n",
    "\n",
    "def filter_signals(signal, lookahead_days):\n",
    "    \"\"\"\n",
    "    Filter out signals in a DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : DataFrame\n",
    "        The long, short, and do nothing signals for each ticker and date\n",
    "    lookahead_days : int\n",
    "        The number of days to look ahead\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    filtered_signal : DataFrame\n",
    "        The filtered long, short, and do nothing signals for each ticker and date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_filter_signals(filter_signals)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View Data\n",
    "Let's view the same chart as before, but with the redundant signals removed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "signal_5 = filter_signals(signal, 5)\n",
    "signal_10 = filter_signals(signal, 10)\n",
    "signal_20 = filter_signals(signal, 20)\n",
    "for signal_data, signal_days in [(signal_5, 5), (signal_10, 10), (signal_20, 20)]:\n",
    "    project_helper.plot_signal(\n",
    "        close[apple_ticker],\n",
    "        signal_data[apple_ticker],\n",
    "        'Long and Short of {} Stock with {} day signal window'.format(apple_ticker, signal_days))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lookahead Close Prices\n",
    "With the trading signal done, we can start working on evaluating how many days to short or long the stocks. In this problem, implement `get_lookahead_prices` to get the close price days ahead in time. You can get the number of days from the variable `lookahead_days`. We'll use the lookahead prices to calculate future returns in another problem."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_lookahead_prices(close, lookahead_days):\n",
    "    \"\"\"\n",
    "    Get the lookahead prices for `lookahead_days` number of days.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    close : DataFrame\n",
    "        Close price for each ticker and date\n",
    "    lookahead_days : int\n",
    "        The number of days to look ahead\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lookahead_prices : DataFrame\n",
    "        The lookahead prices for each ticker and date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_get_lookahead_prices(get_lookahead_prices)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View Data\n",
    "Using the `get_lookahead_prices` function, let's generate lookahead closing prices for 5, 10, and 20 days.\n",
    "\n",
    "Let's also chart a subsection of a few months of the Apple stock instead of years. This will allow you to view the differences between the 5, 10, and 20 day lookaheads. Otherwise, they will mesh together when looking at a chart that is zoomed out."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lookahead_5 = get_lookahead_prices(close, 5)\n",
    "lookahead_10 = get_lookahead_prices(close, 10)\n",
    "lookahead_20 = get_lookahead_prices(close, 20)\n",
    "project_helper.plot_lookahead_prices(\n",
    "    close[apple_ticker].iloc[150:250],\n",
    "    [\n",
    "        (lookahead_5[apple_ticker].iloc[150:250], 5),\n",
    "        (lookahead_10[apple_ticker].iloc[150:250], 10),\n",
    "        (lookahead_20[apple_ticker].iloc[150:250], 20)],\n",
    "    '5, 10, and 20 day Lookahead Prices for Slice of {} Stock'.format(apple_ticker))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lookahead Price Returns\n",
    "Implement `get_return_lookahead` to generate the log price return between the closing price and the lookahead price."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_return_lookahead(close, lookahead_prices):\n",
    "    \"\"\"\n",
    "    Calculate the log returns from the lookahead days to the signal day.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    close : DataFrame\n",
    "        Close price for each ticker and date\n",
    "    lookahead_prices : DataFrame\n",
    "        The lookahead prices for each ticker and date\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lookahead_returns : DataFrame\n",
    "        The lookahead log returns for each ticker and date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_get_return_lookahead(get_return_lookahead)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View Data\n",
    "Using the same lookahead prices and same subsection of the Apple stock from the previous problem, we'll view the lookahead returns.\n",
    "\n",
    "In order to view price returns on the same chart as the stock, a second y-axis will be added. When viewing this chart, the axis for the price of the stock will be on the left side, like previous charts. The axis for price returns will be located on the right side."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "price_return_5 = get_return_lookahead(close, lookahead_5)\n",
    "price_return_10 = get_return_lookahead(close, lookahead_10)\n",
    "price_return_20 = get_return_lookahead(close, lookahead_20)\n",
    "project_helper.plot_price_returns(\n",
    "    close[apple_ticker].iloc[150:250],\n",
    "    [\n",
    "        (price_return_5[apple_ticker].iloc[150:250], 5),\n",
    "        (price_return_10[apple_ticker].iloc[150:250], 10),\n",
    "        (price_return_20[apple_ticker].iloc[150:250], 20)],\n",
    "    '5, 10, and 20 day Lookahead Returns for Slice {} Stock'.format(apple_ticker))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute the Signal Return\n",
    "Using the price returns generate the signal returns."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_signal_return(signal, lookahead_returns):\n",
    "    \"\"\"\n",
    "    Compute the signal returns.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : DataFrame\n",
    "        The long, short, and do nothing signals for each ticker and date\n",
    "    lookahead_returns : DataFrame\n",
    "        The lookahead log returns for each ticker and date\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    signal_return : DataFrame\n",
    "        Signal returns for each ticker and date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_get_signal_return(get_signal_return)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View Data\n",
    "Let's continue using the previous lookahead prices to view the signal returns. Just like before, the axis for the signal returns is on the right side of the chart."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "title_string = '{} day LookaheadSignal Returns for {} Stock'\n",
    "signal_return_5 = get_signal_return(signal_5, price_return_5)\n",
    "signal_return_10 = get_signal_return(signal_10, price_return_10)\n",
    "signal_return_20 = get_signal_return(signal_20, price_return_20)\n",
    "project_helper.plot_signal_returns(\n",
    "    close[apple_ticker],\n",
    "    [\n",
    "        (signal_return_5[apple_ticker], signal_5[apple_ticker], 5),\n",
    "        (signal_return_10[apple_ticker], signal_10[apple_ticker], 10),\n",
    "        (signal_return_20[apple_ticker], signal_20[apple_ticker], 20)],\n",
    "    [title_string.format(5, apple_ticker), title_string.format(10, apple_ticker), title_string.format(20, apple_ticker)])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test for Significance\n",
    "### Histogram\n",
    "Let's plot a histogram of the signal return values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "project_helper.plot_signal_histograms(\n",
    "    [signal_return_5, signal_return_10, signal_return_20],\n",
    "    'Signal Return',\n",
    "    ('5 Days', '10 Days', '20 Days'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question: What do the histograms tell you about the signal returns?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*#TODO: Put Answer In this Cell*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Outliers\n",
    "You might have noticed the outliers in the 10 and 20 day histograms. To better visualize the outliers, let's compare the 5, 10, and 20 day signals returns to normal distributions with the same mean and deviation for each signal return distributions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "project_helper.plot_signal_to_normal_histograms(\n",
    "    [signal_return_5, signal_return_10, signal_return_20],\n",
    "    'Signal Return',\n",
    "    ('5 Days', '10 Days', '20 Days'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kolmogorov-Smirnov Test\n",
    "While you can see the outliers in the histogram, we need to find the stocks that are causing these outlying returns. We'll use the Kolmogorov-Smirnov Test or KS-Test. This test will be applied to teach ticker's signal returns where a long or short signal exits."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Filter out returns that don't have a long or short signal.\n",
    "long_short_signal_returns_5 = signal_return_5[signal_5 != 0].stack()\n",
    "long_short_signal_returns_10 = signal_return_10[signal_10 != 0].stack()\n",
    "long_short_signal_returns_20 = signal_return_20[signal_20 != 0].stack()\n",
    "\n",
    "# Get just ticker and signal return\n",
    "long_short_signal_returns_5 = long_short_signal_returns_5.reset_index().iloc[:, [1,2]]\n",
    "long_short_signal_returns_5.columns = ['ticker', 'signal_return']\n",
    "long_short_signal_returns_10 = long_short_signal_returns_10.reset_index().iloc[:, [1,2]]\n",
    "long_short_signal_returns_10.columns = ['ticker', 'signal_return']\n",
    "long_short_signal_returns_20 = long_short_signal_returns_20.reset_index().iloc[:, [1,2]]\n",
    "long_short_signal_returns_20.columns = ['ticker', 'signal_return']\n",
    "\n",
    "# View some of the data\n",
    "long_short_signal_returns_5.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives you the data to use in the KS-Test.\n",
    "\n",
    "Now it's time to implement the function `calculate_kstest` to use Kolmogorov-Smirnov test (KS test) between a distribution of stock returns (the input dataframe in this case) and each stock's signal returns. Run KS test on a normal distribution against each stock's signal returns. Use [`scipy.stats.kstest`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.kstest.html#scipy-stats-kstest) perform the KS test. When calculating the standard deviation of the signal returns, make sure to set the delta degrees of freedom to 0.\n",
    "\n",
    "For this function, we don't reccommend you try to find a vectorized solution. Instead, you should iterate over the [`groupby`](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.groupby.html) function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.stats import kstest\n",
    "\n",
    "\n",
    "def calculate_kstest(long_short_signal_returns):\n",
    "    \"\"\"\n",
    "    Calculate the KS-Test against the signal returns with a long or short signal.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    long_short_signal_returns : DataFrame\n",
    "        The signal returns which have a signal.\n",
    "        This DataFrame contains two columns, \"ticker\" and \"signal_return\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ks_values : Pandas Series\n",
    "        KS static for all the tickers\n",
    "    p_values : Pandas Series\n",
    "        P value for all the tickers\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "project_tests.test_calculate_kstest(calculate_kstest)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View Data\n",
    "Using the signal returns we created above, let's calculate the ks and p values."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ks_values_5, p_values_5 = calculate_kstest(long_short_signal_returns_5)\n",
    "ks_values_10, p_values_10 = calculate_kstest(long_short_signal_returns_10)\n",
    "ks_values_20, p_values_20 = calculate_kstest(long_short_signal_returns_20)\n",
    "\n",
    "print('ks_values_5')\n",
    "print(ks_values_5.head(10))\n",
    "print('p_values_5')\n",
    "print(p_values_5.head(10))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Find Outliers\n",
    "With the ks and p values calculate, let's find which symbols are the outliers. Implement the `find_outliers` function to find the following outliers:\n",
    "- Symbols that pass the null hypothesis with a p-value less than `pvalue_threshold` **AND** with a KS value above `ks_threshold`.\n",
    "\n",
    "*Note: your function should return symbols that meet both requirements above.*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def find_outliers(ks_values, p_values, ks_threshold, pvalue_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Find outlying symbols using KS values and P-values\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ks_values : Pandas Series\n",
    "        KS static for all the tickers\n",
    "    p_values : Pandas Series\n",
    "        P value for all the tickers\n",
    "    ks_threshold : float\n",
    "        The threshold for the KS statistic\n",
    "    pvalue_threshold : float\n",
    "        The threshold for the p-value\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    outliers : set of str\n",
    "        Symbols that are outliers\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_find_outliers(find_outliers)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View Data\n",
    "Using the `find_outliers` function you implemented, let's see what we found."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ks_threshold = 0.8\n",
    "outliers_5 = find_outliers(ks_values_5, p_values_5, ks_threshold)\n",
    "outliers_10 = find_outliers(ks_values_10, p_values_10, ks_threshold)\n",
    "outliers_20 = find_outliers(ks_values_20, p_values_20, ks_threshold)\n",
    "\n",
    "outlier_tickers = outliers_5.union(outliers_10).union(outliers_20)\n",
    "print('{} Outliers Found:\\n{}'.format(len(outlier_tickers), ', '.join(list(outlier_tickers))))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Show Significance without Outliers\n",
    "Let's compare the 5, 10, and 20 day signals returns without outliers to normal distributions. Also, let's see how the P-Value has changed with the outliers removed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "good_tickers = list(set(close.columns) - outlier_tickers)\n",
    "\n",
    "project_helper.plot_signal_to_normal_histograms(\n",
    "    [signal_return_5[good_tickers], signal_return_10[good_tickers], signal_return_20[good_tickers]],\n",
    "    'Signal Return Without Outliers',\n",
    "    ('5 Days', '10 Days', '20 Days'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's more like it! The returns are closer to a normal distribution. You have finished the research phase of a Breakout Strategy. You can now submit your project.\n",
    "## Submission\n",
    "Now that you're done with the project, it's time to submit it. Click the submit button in the bottom right. One of our reviewers will give you feedback on your project with a pass or not passed grade. You can continue to the next section while you wait for feedback."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('py38-jupyter': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "0f07e1c58239e8b717e5422cc9fb22b547804f82b0978892fdbb8b07a6a4651a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}